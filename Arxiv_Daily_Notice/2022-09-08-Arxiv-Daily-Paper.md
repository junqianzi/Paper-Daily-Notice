# New submissions for Thu,  8 Sep 22
## Keyword: SLAM
There is no result 
## Keyword: odometry
### Picking Up Speed: Continuous-Time Lidar-Only Odometry using Doppler  Velocity Measurements
 - **Authors:** Yuchen Wu, David J. Yoon, Keenan Burnett, Soeren Kammel, Yi Chen, Heethesh Vhavle, Timothy D. Barfoot
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2209.03304
 - **Pdf link:** https://arxiv.org/pdf/2209.03304
 - **Abstract**
 Frequency-Modulated Continuous-Wave (FMCW) lidar is a recently emerging technology that additionally enables per-return instantaneous relative radial velocity measurements via the Doppler effect. In this letter, we present the first continuous-time lidar-only odometry algorithm using these Doppler velocity measurements from an FMCW lidar to aid odometry in geometrically degenerate environments. We apply an existing continuous-time framework that efficiently estimates the vehicle trajectory using Gaussian process regression to compensate for motion distortion due to the scanning-while-moving nature of any mechanically actuated lidar (FMCW and non-FMCW). We evaluate our proposed algorithm on several real-world datasets, including publicly available ones and datasets we collected. Our algorithm outperforms the only existing method that also uses Doppler velocity measurements, and we study difficult conditions where including this extra information greatly improves performance. We additionally demonstrate state-of-the-art performance of lidar-only odometry with and without using Doppler velocity measurements in nominal conditions. Code for this project can be found at: https://github.com/utiasASRL/steam_icp.
## Keyword: livox
There is no result 
## Keyword: loam
There is no result 
## Keyword: lidar
### MSMDFusion: Fusing LiDAR and Camera at Multiple Scales with Multi-Depth  Seeds for 3D Object Detection
 - **Authors:** Yang Jiao, Zequn Jie, Shaoxiang Chen, Jingjing Chen, Xiaolin Wei, Lin Ma, Yu-Gang Jiang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2209.03102
 - **Pdf link:** https://arxiv.org/pdf/2209.03102
 - **Abstract**
 Fusing LiDAR and camera information is essential for achieving accurate and reliable 3D object detection in autonomous driving systems. However, this is challenging due to the difficulty of combining multi-granularity geometric and semantic features from two drastically different modalities. Recent approaches aim at exploring the semantic densities of camera features through lifting points in 2D camera images (referred to as seeds) into 3D space for fusion, and they can be roughly divided into 1) early fusion of raw points that aims at augmenting the 3D point cloud at the early input stage, and 2) late fusion of BEV (bird-eye view) maps that merges LiDAR and camera BEV features before the detection head. While both have their merits in enhancing the representation power of the combined features, this single-level fusion strategy is a suboptimal solution to the aforementioned challenge. Their major drawbacks are the inability to interact the multi-granularity semantic features from two distinct modalities sufficiently. To this end, we propose a novel framework that focuses on the multi-scale progressive interaction of the multi-granularity LiDAR and camera features. Our proposed method, abbreviated as MDMSFusion, achieves state-of-the-art results in 3D object detection, with 69.1 mAP and 71.8 NDS on nuScenes validation set, and 70.8 mAP and 73.2 NDS on nuScenes test set, which rank 1st and 2nd respectively among single-model non-ensemble approaches by the time of submission.
### On the Importance of Quantifying Visibility for Autonomous Vehicles  under Extreme Precipitation
 - **Authors:** Clément Courcelle, Dominic Baril, François Pomerleau, Johann Laconte
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2209.03226
 - **Pdf link:** https://arxiv.org/pdf/2209.03226
 - **Abstract**
 In the context of autonomous driving, vehicles are inherently bound to encounter more extreme weather during which public safety must be ensured. As climate is quickly changing, the frequency of heavy snowstorms is expected to increase and become a major threat to safe navigation. While there is much literature aiming to improve navigation resiliency to winter conditions, there is a lack of standard metrics to quantify the loss of visibility of lidar sensors related to precipitation. This chapter proposes a novel metric to quantify the lidar visibility loss in real time, relying on the notion of visibility from the meteorology research field. We evaluate this metric on the Canadian Adverse Driving Conditions (CADC) dataset, correlate it with the performance of a state-of-the-art lidar-based localization algorithm, and evaluate the benefit of filtering point clouds before the localization process. We show that the Iterative Closest Point (ICP) algorithm is surprisingly robust against snowfalls, but abrupt events, such as snow gusts, can greatly hinder its accuracy. We discuss such events and demonstrate the need for better datasets focusing on these extreme events to quantify their effect.
### Picking Up Speed: Continuous-Time Lidar-Only Odometry using Doppler  Velocity Measurements
 - **Authors:** Yuchen Wu, David J. Yoon, Keenan Burnett, Soeren Kammel, Yi Chen, Heethesh Vhavle, Timothy D. Barfoot
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2209.03304
 - **Pdf link:** https://arxiv.org/pdf/2209.03304
 - **Abstract**
 Frequency-Modulated Continuous-Wave (FMCW) lidar is a recently emerging technology that additionally enables per-return instantaneous relative radial velocity measurements via the Doppler effect. In this letter, we present the first continuous-time lidar-only odometry algorithm using these Doppler velocity measurements from an FMCW lidar to aid odometry in geometrically degenerate environments. We apply an existing continuous-time framework that efficiently estimates the vehicle trajectory using Gaussian process regression to compensate for motion distortion due to the scanning-while-moving nature of any mechanically actuated lidar (FMCW and non-FMCW). We evaluate our proposed algorithm on several real-world datasets, including publicly available ones and datasets we collected. Our algorithm outperforms the only existing method that also uses Doppler velocity measurements, and we study difficult conditions where including this extra information greatly improves performance. We additionally demonstrate state-of-the-art performance of lidar-only odometry with and without using Doppler velocity measurements in nominal conditions. Code for this project can be found at: https://github.com/utiasASRL/steam_icp.
### Detection and Mapping of Specular Surfaces Using Multibounce Lidar  Returns
 - **Authors:** Connor Henley, Siddharth Somasundaram, Joseph Hollmann, Ramesh Raskar
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Image and Video Processing (eess.IV)
 - **Arxiv link:** https://arxiv.org/abs/2209.03336
 - **Pdf link:** https://arxiv.org/pdf/2209.03336
 - **Abstract**
 We propose methods that use specular, multibounce lidar returns to detect and map specular surfaces that might be invisible to conventional lidar systems that rely on direct, single-scatter returns. We derive expressions that relate the time- and angle-of-arrival of these multibounce returns to scattering points on the specular surface, and then use these expressions to formulate techniques for retrieving specular surface geometry when the scene is scanned by a single beam or illuminated with a multi-beam flash. We also consider the special case of transparent specular surfaces, for which surface reflections can be mixed together with light that scatters off of objects lying behind the surface.
## Keyword: loop detection
There is no result 
## Keyword: nerf
There is no result 
## Keyword: mapping
### Unifying Effects of Direct and Relational Associations for Visual  Communication
 - **Authors:** Melissa A. Schoenlein, Johnny Campos, Kevin J. Lande, Laurent Lessard, Karen B. Schloss
 - **Subjects:** Human-Computer Interaction (cs.HC)
 - **Arxiv link:** https://arxiv.org/abs/2209.02782
 - **Pdf link:** https://arxiv.org/pdf/2209.02782
 - **Abstract**
 People have expectations about how colors map to concepts in visualizations, and they are better at interpreting visualizations that match their expectations. Traditionally, studies on these expectations (inferred mappings) distinguished distinct factors relevant for visualizations of categorical vs. continuous information. Studies on categorical information focused on direct associations (e.g., mangos are associated with yellows) whereas studies on continuous information focused on relational associations (e.g., darker colors map to larger quantities; dark-is-more bias). We unite these two areas within a single framework of assignment inference. Assignment inference is the process by which people infer mappings between perceptual features and concepts represented in encoding systems. Observers infer globally optimal assignments by maximizing the "merit," or "goodness," of each possible assignment. Previous work on assignment inference focused on visualizations of categorical information. We extend this approach to visualizations of continuous data by (a) broadening the notion of merit to include relational associations and (b) developing a method for combining multiple (sometimes conflicting) sources of merit to predict people's inferred mappings. We developed and tested our model on data from experiments in which participants interpreted colormap data visualizations, representing fictitious data about environmental concepts (sunshine, shade, wild fire, ocean water, glacial ice). We found both direct and relational associations contribute independently to inferred mappings. These results can be used to optimize visualization design to facilitate visual communication.
### Optimal Sensor Placement in Body Surface Networks using Gaussian  Processes
 - **Authors:** Emad Alenany, Changqing Cheng
 - **Subjects:** Machine Learning (cs.LG); Signal Processing (eess.SP)
 - **Arxiv link:** https://arxiv.org/abs/2209.02912
 - **Pdf link:** https://arxiv.org/pdf/2209.02912
 - **Abstract**
 This paper explores a new sequential selection framework for the optimal sensor placement (OSP) in Electrocardiography imaging networks (ECGI). The proposed methodology incorporates the use a recent experimental design method for the sequential selection of landmarkings on biological objects, namely, Gaussian process landmarking (GPLMK) for better exploration of the candidate sensors. The two experimental design methods work as a source of the training and the validation locations which is fitted using a spatiotemporal Gaussian process (STGP). The STGP is fitted using the training set to predict for the current validation set generated using GPLMK, and the sensor with the largest prediction absolute error is selected from the current validation set and added to the selected sensors. Next, a new validation set is generated and predicted using the current training set. The process continues until selecting a specific number of sensor locations. The study is conducted on a dataset of body surface potential mapping (BSPM) of 352 electrodes of four human subjects. A number of 30 sensor locations is selected using the proposed algorithm. The selected sensor locations achieved average $R^2 = 94.40 \%$ for estimating the whole-body QRS segment. The proposed method adds to design efforts for a more clinically practical ECGI system by improving its wearability and reduce the design cost as well.
### Adaptive Passivity-Based Pose Tracking Control of Cable-Driven Parallel  Robots for Multiple Attitude Parameterizations
 - **Authors:** Sze Kwan Cheah, Alex Hayes, Ryan J. Caverly
 - **Subjects:** Robotics (cs.RO); Systems and Control (eess.SY)
 - **Arxiv link:** https://arxiv.org/abs/2209.03250
 - **Pdf link:** https://arxiv.org/pdf/2209.03250
 - **Abstract**
 The proposed control method uses an adaptive feedforward-based controller to establish a passive input-output mapping for the CDPR that is used alongside a linear time-invariant strictly positive real feedback controller to guarantee robust closed-loop input-output stability and asymptotic pose trajectory tracking via the passivity theorem. A novelty of the proposed controller is its formulation for use with a range of payload attitude parameterizations, including any unconstrained attitude parameterization, the quaternion, or the direction cosine matrix (DCM). The performance and robustness of the proposed controller is demonstrated through numerical simulations of a CDPR with rigid and flexible cables. The results demonstrate the importance of carefully defining the CDPR's pose error, which is performed in multiplicative fashion when using the quaternion and DCM, and in a specific additive fashion when using unconstrained attitude parameters (e.g., an Euler-angle sequence).
### Measuring the Interpretability of Unsupervised Representations via  Quantized Reverse Probing
 - **Authors:** Iro Laina, Yuki M. Asano, Andrea Vedaldi
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2209.03268
 - **Pdf link:** https://arxiv.org/pdf/2209.03268
 - **Abstract**
 Self-supervised visual representation learning has recently attracted significant research interest. While a common way to evaluate self-supervised representations is through transfer to various downstream tasks, we instead investigate the problem of measuring their interpretability, i.e. understanding the semantics encoded in raw representations. We formulate the latter as estimating the mutual information between the representation and a space of manually labelled concepts. To quantify this we introduce a decoding bottleneck: information must be captured by simple predictors, mapping concepts to clusters in representation space. This approach, which we call reverse linear probing, provides a single number sensitive to the semanticity of the representation. This measure is also able to detect when the representation contains combinations of concepts (e.g., "red apple") instead of just individual attributes ("red" and "apple" independently). Finally, we propose to use supervised classifiers to automatically label large datasets in order to enrich the space of concepts used for probing. We use our method to evaluate a large number of self-supervised representations, ranking them by interpretability, highlight the differences that emerge compared to the standard evaluation with linear probes and discuss several qualitative insights. Code at: {\scriptsize{\url{https://github.com/iro-cp/ssl-qrp}}}.
## Keyword: localization
### Localizing Load-Altering Attacks Against Power Grids Using Deep Capsule  Nets
 - **Authors:** Hamidreza Jahangir, Subhash Lakshminarayana, Carsten Maple
 - **Subjects:** Cryptography and Security (cs.CR); Systems and Control (eess.SY)
 - **Arxiv link:** https://arxiv.org/abs/2209.02809
 - **Pdf link:** https://arxiv.org/pdf/2209.02809
 - **Abstract**
 Recent research has shown that the security of power grids can be seriously threatened by botnet-type cyber attacks that target a large number of high-wattage smart electrical appliances owned by end-users. Accurate detection and localization of such attacks is of critical importance in limiting the damage. To this end, the paper proposes a novel technique using capsule networks (CNs) tailored to the power grid security application that uses the frequency and phase angle data monitored by phasor measurement units (PMUs). With the benefit of vector output from capsules and dynamic routing agreements between them, CNs can obtain accurate detection and localization performance. To demonstrate the efficiency of the suggested technique, we compare the developed CN with benchmark data-driven methodologies, including two-dimensional convolutional neural networks (2D-CNN), one-dimensional CNN (1D-CNN), deep multi-layer perceptrons (MLP), and support vector machines (SVM). Simulations are performed on IEEE 14-, 39-, and 57-bus systems, considering various real-world issues such as PMU delays, noisy data, and missing data points. The results show that CNs significantly outperform other techniques, thus making them suitable for the aforementioned cyber security applications.
### Toward Data-Driven Radar STAP
 - **Authors:** Shyam Venkatasubramanian, Sandeep Gogineni, Bosung Kang, Ali Pezeshki, Muralidhar Rangaswamy, Vahid Tarokh
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Signal Processing (eess.SP)
 - **Arxiv link:** https://arxiv.org/abs/2209.02890
 - **Pdf link:** https://arxiv.org/pdf/2209.02890
 - **Abstract**
 Catalyzed by the recent emergence of site-specific, high-fidelity radio frequency (RF) modeling and simulation tools purposed for radar, data-driven formulations of classical methods in radar have rapidly grown in popularity over the past decade. Despite this surge, limited focus has been directed toward the theoretical foundations of these classical methods. In this regard, as part of our ongoing data-driven approach to radar space-time adaptive processing (STAP), we analyze the asymptotic performance guarantees of select subspace separation methods in the context of radar target localization, and augment this analysis through a proposed deep learning framework for target location estimation. In our approach, we generate comprehensive datasets by randomly placing targets of variable strengths in predetermined constrained areas using RFView, a site-specific RF modeling and simulation tool developed by ISL Inc. For each radar return signal from these constrained areas, we generate heatmap tensors in range, azimuth, and elevation of the normalized adaptive matched filter (NAMF) test statistic, and of the output power of a generalized sidelobe canceller (GSC). Using our deep learning framework, we estimate target locations from these heatmap tensors to demonstrate the feasibility of and significant improvements provided by our data-driven approach in matched and mismatched settings.
### Ultra-low-power Range Error Mitigation for Ultra-wideband Precise  Localization
 - **Authors:** Simone Angarano, Francesco Salvetti, Vittorio Mazzia, Giovanni Fantin, Dario Gandini, Marcello Chiaberge
 - **Subjects:** Machine Learning (cs.LG); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2209.03021
 - **Pdf link:** https://arxiv.org/pdf/2209.03021
 - **Abstract**
 Precise and accurate localization in outdoor and indoor environments is a challenging problem that currently constitutes a significant limitation for several practical applications. Ultra-wideband (UWB) localization technology represents a valuable low-cost solution to the problem. However, non-line-of-sight (NLOS) conditions and complexity of the specific radio environment can easily introduce a positive bias in the ranging measurement, resulting in highly inaccurate and unsatisfactory position estimation. In the light of this, we leverage the latest advancement in deep neural network optimization techniques and their implementation on ultra-low-power microcontrollers to introduce an effective range error mitigation solution that provides corrections in either NLOS or LOS conditions with a few mW of power. Our extensive experimentation endorses the advantages and improvements of our low-cost and power-efficient methodology.
### Passive and Privacy-preserving Human Localization via mmWave Access  Points for Social Distancing
 - **Authors:** Francesco Devoti, Vincenzo Sciancalepore, Xavier Costa-Perez
 - **Subjects:** Networking and Internet Architecture (cs.NI)
 - **Arxiv link:** https://arxiv.org/abs/2209.03099
 - **Pdf link:** https://arxiv.org/pdf/2209.03099
 - **Abstract**
 The pandemic outbreak has profoundly changed our life, especially our social habits and communication behaviors. While this dramatic shock has heavily impacted human interaction rules, novel localization techniques are emerging to help society in complying with new policies, such as social distancing. Wireless sensing and machine learning are well suited to alleviate viruses propagation in a privacy-preserving manner. However, its wide deployment requires cost-effective installation and operational solutions. In public environments, individual localization information-such as social distancing-needs to be monitored to avoid safety threats when not properly observed. To this end, the high penetration of wireless devices can be exploited to continuously analyze-and-learn the propagation environment, thereby passively detecting breaches and triggering alerts if required. In this paper, we describe a novel passive and privacy-preserving human localization solution that relies on the directive transmission properties of mmWave communications to monitor social distancing and notify people in the area in case of violations. Thus, addressing the social distancing challenge in a privacy-preserving and cost-efficient manner. Our solution provides an overall accuracy of about 99% in the tested scenarios.
### On the Importance of Quantifying Visibility for Autonomous Vehicles  under Extreme Precipitation
 - **Authors:** Clément Courcelle, Dominic Baril, François Pomerleau, Johann Laconte
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2209.03226
 - **Pdf link:** https://arxiv.org/pdf/2209.03226
 - **Abstract**
 In the context of autonomous driving, vehicles are inherently bound to encounter more extreme weather during which public safety must be ensured. As climate is quickly changing, the frequency of heavy snowstorms is expected to increase and become a major threat to safe navigation. While there is much literature aiming to improve navigation resiliency to winter conditions, there is a lack of standard metrics to quantify the loss of visibility of lidar sensors related to precipitation. This chapter proposes a novel metric to quantify the lidar visibility loss in real time, relying on the notion of visibility from the meteorology research field. We evaluate this metric on the Canadian Adverse Driving Conditions (CADC) dataset, correlate it with the performance of a state-of-the-art lidar-based localization algorithm, and evaluate the benefit of filtering point clouds before the localization process. We show that the Iterative Closest Point (ICP) algorithm is surprisingly robust against snowfalls, but abrupt events, such as snow gusts, can greatly hinder its accuracy. We discuss such events and demonstrate the need for better datasets focusing on these extreme events to quantify their effect.
### Accurate Cooperative Sensor Fusion by Parameterized Covariance  Generation for Sensing and Localization Pipelines in CAVs
 - **Authors:** Edward Andert, Aviral Shrivastava
 - **Subjects:** Robotics (cs.RO); Multiagent Systems (cs.MA)
 - **Arxiv link:** https://arxiv.org/abs/2209.03306
 - **Pdf link:** https://arxiv.org/pdf/2209.03306
 - **Abstract**
 A major challenge in cooperative sensing is to weight the measurements taken from the various sources to get an accurate result. Ideally, the weights should be inversely proportional to the error in the sensing information. However, previous cooperative sensor fusion approaches for autonomous vehicles use a fixed error model, in which the covariance of a sensor and its recognizer pipeline is just the mean of the measured covariance for all sensing scenarios. The approach proposed in this paper estimates error using key predictor terms that have high correlation with sensing and localization accuracy for accurate covariance estimation of each sensor observation. We adopt a tiered fusion model consisting of local and global sensor fusion steps. At the local fusion level, we add in a covariance generation stage using the error model for each sensor and the measured distance to generate the expected covariance matrix for each observation. At the global sensor fusion stage we add an additional stage to generate the localization covariance matrix from the key predictor term velocity and combines that with the covariance generated from the local fusion for accurate cooperative sensing. To showcase our method, we built a set of 1/10 scale model autonomous vehicles with scale accurate sensing capabilities and classified the error characteristics against a motion capture system. Results show an average and max improvement in RMSE when detecting vehicle positions of 1.42x and 1.78x respectively in a four-vehicle cooperative fusion scenario when using our error model versus a typical fixed error model.
## Keyword: transformer
### Fusion of Satellite Images and Weather Data with Transformer Networks  for Downy Mildew Disease Detection
 - **Authors:** William Maillet, Maryam Ouhami, Adel Hafiane
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2209.02797
 - **Pdf link:** https://arxiv.org/pdf/2209.02797
 - **Abstract**
 Crop diseases significantly affect the quantity and quality of agricultural production. In a context where the goal of precision agriculture is to minimize or even avoid the use of pesticides, weather and remote sensing data with deep learning can play a pivotal role in detecting crop diseases, allowing localized treatment of crops. However, combining heterogeneous data such as weather and images remains a hot topic and challenging task. Recent developments in transformer architectures have shown the possibility of fusion of data from different domains, for instance text-image. The current trend is to custom only one transformer to create a multimodal fusion model. Conversely, we propose a new approach to realize data fusion using three transformers. In this paper, we first solved the missing satellite images problem, by interpolating them with a ConvLSTM model. Then, proposed a multimodal fusion architecture that jointly learns to process visual and weather information. The architecture is built from three main components, a Vision Transformer and two transformer-encoders, allowing to fuse both image and weather modalities. The results of the proposed method are promising achieving 97\% overall accuracy.
### Visual Transformer for Soil Classification
 - **Authors:** Aaryan Jagetia, Umang Goenka, Priyadarshini Kumari, Mary Samuel
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2209.02950
 - **Pdf link:** https://arxiv.org/pdf/2209.02950
 - **Abstract**
 Our food security is built on the foundation of soil. Farmers would be unable to feed us with fiber, food, and fuel if the soils were not healthy. Accurately predicting the type of soil helps in planning the usage of the soil and thus increasing productivity. This research employs state-of-the-art Visual Transformers and also compares performance with different models such as SVM, Alexnet, Resnet, and CNN. Furthermore, this study also focuses on differentiating different Visual Transformers architectures. For the classification of soil type, the dataset consists of 4 different types of soil samples such as alluvial, red, black, and clay. The Visual Transformer model outperforms other models in terms of both test and train accuracies by attaining 98.13% on training and 93.62% while testing. The performance of the Visual Transformer exceeds the performance of other models by at least 2%. Hence, the novel Visual Transformers can be used for Computer Vision tasks including Soil Classification.
### Semi-supervised Crowd Counting via Density Agency
 - **Authors:** Hui Lin, Zhiheng Ma, Xiaopeng Hong, Yaowei Wang, Zhou Su
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2209.02955
 - **Pdf link:** https://arxiv.org/pdf/2209.02955
 - **Abstract**
 In this paper, we propose a new agency-guided semi-supervised counting approach. First, we build a learnable auxiliary structure, namely the density agency to bring the recognized foreground regional features close to corresponding density sub-classes (agents) and push away background ones. Second, we propose a density-guided contrastive learning loss to consolidate the backbone feature extractor. Third, we build a regression head by using a transformer structure to refine the foreground features further. Finally, an efficient noise depression loss is provided to minimize the negative influence of annotation noises. Extensive experiments on four challenging crowd counting datasets demonstrate that our method achieves superior performance to the state-of-the-art semi-supervised counting methods by a large margin. Code is available.
### Adam Mickiewicz University at WMT 2022: NER-Assisted and Quality-Aware  Neural Machine Translation
 - **Authors:** Artur Nowakowski, Gabriela Pałka, Kamil Guttmann, Mikołaj Pokrywka
 - **Subjects:** Computation and Language (cs.CL)
 - **Arxiv link:** https://arxiv.org/abs/2209.02962
 - **Pdf link:** https://arxiv.org/pdf/2209.02962
 - **Abstract**
 This paper presents Adam Mickiewicz University's (AMU) submissions to the constrained track of the WMT 2022 General MT Task. We participated in the Ukrainian $\leftrightarrow$ Czech translation directions. The systems are a weighted ensemble of four models based on the Transformer (big) architecture. The models use source factors to utilize the information about named entities present in the input. Each of the models in the ensemble was trained using only the data provided by the shared task organizers. A noisy back-translation technique was used to augment the training corpora. One of the models in the ensemble is a document-level model, trained on parallel and synthetic longer sequences. During the sentence-level decoding process, the ensemble generated the n-best list. The n-best list was merged with the n-best list generated by a single document-level model which translated multiple sentences at a time. Finally, existing quality estimation models and minimum Bayes risk decoding were used to rerank the n-best list so that the best hypothesis was chosen according to the COMET evaluation metric. According to the automatic evaluation results, our systems rank first in both translation directions.
### Improving the Cross-Lingual Generalisation in Visual Question Answering
 - **Authors:** Farhad Nooralahzadeh, Rico Sennrich
 - **Subjects:** Computation and Language (cs.CL)
 - **Arxiv link:** https://arxiv.org/abs/2209.02982
 - **Pdf link:** https://arxiv.org/pdf/2209.02982
 - **Abstract**
 While several benefits were realized for multilingual vision-language pretrained models, recent benchmarks across various tasks and languages showed poor cross-lingual generalisation when multilingually pre-trained vision-language models are applied to non-English data, with a large gap between (supervised) English performance and (zero-shot) cross-lingual transfer. In this work, we explore the poor performance of these models on a zero-shot cross-lingual visual question answering (VQA) task, where models are fine-tuned on English visual-question data and evaluated on 7 typologically diverse languages. We improve cross-lingual transfer with three strategies: (1) we introduce a linguistic prior objective to augment the cross-entropy loss with a similarity-based loss to guide the model during training, (2) we learn a task-specific subnetwork that improves cross-lingual generalisation and reduces variance without model modification, (3) we augment training examples using synthetic code-mixing to promote alignment of embeddings between source and target languages. Our experiments on xGQA using the pretrained multilingual multimodal transformers UC2 and M3P demonstrate the consistent effectiveness of the proposed fine-tuning strategy for 7 languages, outperforming existing transfer methods with sparse models. Code and data to reproduce our findings are publicly available.
### Auto-TransRL: Autonomous Composition of Vision Pipelines for Robotic  Perception
 - **Authors:** Aditya Kapoor, Nijil George, Vartika Sengar, Vighnesh Vatsal, Jayavardhana Gubbi
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV); Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2209.02991
 - **Pdf link:** https://arxiv.org/pdf/2209.02991
 - **Abstract**
 Creating a vision pipeline for different datasets to solve a computer vision task is a complex and time consuming process. Currently, these pipelines are developed with the help of domain experts. Moreover, there is no systematic structure to construct a vision pipeline apart from relying on experience, trial and error or using template-based approaches. As the search space for choosing suitable algorithms for achieving a particular vision task is large, human exploration for finding a good solution requires time and effort. To address the following issues, we propose a dynamic and data-driven way to identify an appropriate set of algorithms that would be fit for building the vision pipeline in order to achieve the goal task. We introduce a Transformer Architecture complemented with Deep Reinforcement Learning to recommend algorithms that can be incorporated at different stages of the vision workflow. This system is both robust and adaptive to dynamic changes in the environment. Experimental results further show that our method also generalizes well to recommend algorithms that have not been used while training and hence alleviates the need of retraining the system on a new set of algorithms introduced during test time.
### A multiclass Q-NLP sentiment analysis experiment using DisCoCat
 - **Authors:** Victor Martinez, Guilhaume Leroy-Meline
 - **Subjects:** Computation and Language (cs.CL); Emerging Technologies (cs.ET)
 - **Arxiv link:** https://arxiv.org/abs/2209.03152
 - **Pdf link:** https://arxiv.org/pdf/2209.03152
 - **Abstract**
 Sentiment analysis is a branch of Natural Language Processing (NLP) which goal is to assign sentiments or emotions to particular sentences or words. Performing this task is particularly useful for companies wishing to take into account customer feedback through chatbots or verbatim. This has been done extensively in the literature using various approaches, ranging from simple models to deep transformer neural networks. In this paper, we will tackle sentiment analysis in the Noisy Intermediate Scale Computing (NISQ) era, using the DisCoCat model of language. We will first present the basics of quantum computing and the DisCoCat model. This will enable us to define a general framework to perform NLP tasks on a quantum computer. We will then extend the two-class classification that was performed by Lorenz et al. (2021) to a four-class sentiment analysis experiment on a much larger dataset, showing the scalability of such a framework.
### On the Effectiveness of Compact Biomedical Transformers
 - **Authors:** Omid Rohanian, Mohammadmahdi Nouriborji, Samaneh Kouchaki, David A. Clifton
 - **Subjects:** Computation and Language (cs.CL); Machine Learning (cs.LG)
 - **Arxiv link:** https://arxiv.org/abs/2209.03182
 - **Pdf link:** https://arxiv.org/pdf/2209.03182
 - **Abstract**
 Language models pre-trained on biomedical corpora, such as BioBERT, have recently shown promising results on downstream biomedical tasks. Many existing pre-trained models, on the other hand, are resource-intensive and computationally heavy owing to factors such as embedding size, hidden dimension, and number of layers. The natural language processing (NLP) community has developed numerous strategies to compress these models utilising techniques such as pruning, quantisation, and knowledge distillation, resulting in models that are considerably faster, smaller, and subsequently easier to use in practice. By the same token, in this paper we introduce six lightweight models, namely, BioDistilBERT, BioTinyBERT, BioMobileBERT, DistilBioBERT, TinyBioBERT, and CompactBioBERT which are obtained either by knowledge distillation from a biomedical teacher or continual learning on the Pubmed dataset via the Masked Language Modelling (MLM) objective. We evaluate all of our models on three biomedical tasks and compare them with BioBERT-v1.1 to create efficient lightweight models that perform on par with their larger counterparts. All the models will be publicly available on our Huggingface profile at https://huggingface.co/nlpie and the codes used to run the experiments will be available at https://github.com/nlpie-research/Compact-Biomedical-Transformers.
### AutoPruner: Transformer-Based Call Graph Pruning
 - **Authors:** Thanh Le-Cong, Hong Jin Kang, Truong Giang Nguyen, Stefanus Agus Haryono, David Lo, Xuan-Bach D. Le, Huynh Quyet Thang
 - **Subjects:** Software Engineering (cs.SE); Artificial Intelligence (cs.AI)
 - **Arxiv link:** https://arxiv.org/abs/2209.03230
 - **Pdf link:** https://arxiv.org/pdf/2209.03230
 - **Abstract**
 Constructing a static call graph requires trade-offs between soundness and precision. Program analysis techniques for constructing call graphs are unfortunately usually imprecise. To address this problem, researchers have recently proposed call graph pruning empowered by machine learning to post-process call graphs constructed by static analysis. A machine learning model is built to capture information from the call graph by extracting structural features for use in a random forest classifier. It then removes edges that are predicted to be false positives. Despite the improvements shown by machine learning models, they are still limited as they do not consider the source code semantics and thus often are not able to effectively distinguish true and false positives. In this paper, we present a novel call graph pruning technique, AutoPruner, for eliminating false positives in call graphs via both statistical semantic and structural analysis. Given a call graph constructed by traditional static analysis tools, AutoPruner takes a Transformer-based approach to capture the semantic relationships between the caller and callee functions associated with each edge in the call graph. To do so, AutoPruner fine-tunes a model of code that was pre-trained on a large corpus to represent source code based on descriptions of its semantics. Next, the model is used to extract semantic features from the functions related to each edge in the call graph. AutoPruner uses these semantic features together with the structural features extracted from the call graph to classify each edge via a feed-forward neural network. Our empirical evaluation on a benchmark dataset of real-world programs shows that AutoPruner outperforms the state-of-the-art baselines, improving on F-measure by up to 13% in identifying false-positive edges in a static call graph.
## Keyword: autonomous driving
### MSMDFusion: Fusing LiDAR and Camera at Multiple Scales with Multi-Depth  Seeds for 3D Object Detection
 - **Authors:** Yang Jiao, Zequn Jie, Shaoxiang Chen, Jingjing Chen, Xiaolin Wei, Lin Ma, Yu-Gang Jiang
 - **Subjects:** Computer Vision and Pattern Recognition (cs.CV)
 - **Arxiv link:** https://arxiv.org/abs/2209.03102
 - **Pdf link:** https://arxiv.org/pdf/2209.03102
 - **Abstract**
 Fusing LiDAR and camera information is essential for achieving accurate and reliable 3D object detection in autonomous driving systems. However, this is challenging due to the difficulty of combining multi-granularity geometric and semantic features from two drastically different modalities. Recent approaches aim at exploring the semantic densities of camera features through lifting points in 2D camera images (referred to as seeds) into 3D space for fusion, and they can be roughly divided into 1) early fusion of raw points that aims at augmenting the 3D point cloud at the early input stage, and 2) late fusion of BEV (bird-eye view) maps that merges LiDAR and camera BEV features before the detection head. While both have their merits in enhancing the representation power of the combined features, this single-level fusion strategy is a suboptimal solution to the aforementioned challenge. Their major drawbacks are the inability to interact the multi-granularity semantic features from two distinct modalities sufficiently. To this end, we propose a novel framework that focuses on the multi-scale progressive interaction of the multi-granularity LiDAR and camera features. Our proposed method, abbreviated as MDMSFusion, achieves state-of-the-art results in 3D object detection, with 69.1 mAP and 71.8 NDS on nuScenes validation set, and 70.8 mAP and 73.2 NDS on nuScenes test set, which rank 1st and 2nd respectively among single-model non-ensemble approaches by the time of submission.
### On the Importance of Quantifying Visibility for Autonomous Vehicles  under Extreme Precipitation
 - **Authors:** Clément Courcelle, Dominic Baril, François Pomerleau, Johann Laconte
 - **Subjects:** Robotics (cs.RO)
 - **Arxiv link:** https://arxiv.org/abs/2209.03226
 - **Pdf link:** https://arxiv.org/pdf/2209.03226
 - **Abstract**
 In the context of autonomous driving, vehicles are inherently bound to encounter more extreme weather during which public safety must be ensured. As climate is quickly changing, the frequency of heavy snowstorms is expected to increase and become a major threat to safe navigation. While there is much literature aiming to improve navigation resiliency to winter conditions, there is a lack of standard metrics to quantify the loss of visibility of lidar sensors related to precipitation. This chapter proposes a novel metric to quantify the lidar visibility loss in real time, relying on the notion of visibility from the meteorology research field. We evaluate this metric on the Canadian Adverse Driving Conditions (CADC) dataset, correlate it with the performance of a state-of-the-art lidar-based localization algorithm, and evaluate the benefit of filtering point clouds before the localization process. We show that the Iterative Closest Point (ICP) algorithm is surprisingly robust against snowfalls, but abrupt events, such as snow gusts, can greatly hinder its accuracy. We discuss such events and demonstrate the need for better datasets focusing on these extreme events to quantify their effect.
